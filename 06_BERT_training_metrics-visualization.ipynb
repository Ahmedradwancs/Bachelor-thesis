{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34306390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 View Results\n",
    "df = pd.read_csv(\"./experiment_results.csv\")\n",
    "df_sorted = df.sort_values(by=\"Test_F1\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\n✅ All Experiments Completed — Summary Table:\\n\")\n",
    "display(df_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150d15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(\"labeled_cases_combined.csv\")\n",
    "df[\"class\"] = df[\"class\"].map({\"Usability\": 1, \"Not Usability\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"class\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b344290",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"description\"]\n",
    "y = df[\"class\"]\n",
    "\n",
    "# Stratified 10% test set\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.10, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Reset test lists\n",
    "X_test = X_test.tolist()\n",
    "y_test = y_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Dataset\n",
    "class TechSupportDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"label\": torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "test_loader = DataLoader(TechSupportDataset(X_test, y_test, tokenizer), batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.bert.config.hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.classifier(outputs.pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e1f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single confusion matrix + ROC\n",
    "def plot_confusion_and_roc(y_true, y_prob, y_pred, title_prefix, filename_prefix):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    labels = [\"Non-Usability\", \"Usability\"]\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, ax=axs[0])\n",
    "    axs[0].set_title(f\"{title_prefix} - Confusion Matrix\")\n",
    "    axs[0].set_xlabel(\"Predicted\")\n",
    "    axs[0].set_ylabel(\"Actual\")\n",
    "\n",
    "    axs[1].plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "    axs[1].plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    axs[1].set_title(f\"{title_prefix} - ROC Curve\")\n",
    "    axs[1].set_xlabel(\"False Positive Rate\")\n",
    "    axs[1].set_ylabel(\"True Positive Rate\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = f\"{filename_prefix}_confusion_roc.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "    return filename, fpr, tpr, roc_auc\n",
    "\n",
    "# Plot all 3 confusion matrices and all 3 ROC curves in one image\n",
    "def plot_combined_confusion_and_roc(models_outputs, save_prefix=\"combined\"):\n",
    "    fig_cm, axs_cm = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    fig_roc, ax_roc = plt.subplots(figsize=(6, 5))\n",
    "    labels = [\"Non-Usability\", \"Usability\"]\n",
    "\n",
    "    for i, (layers, y_true, y_pred, y_prob, fpr, tpr, roc_auc) in enumerate(models_outputs):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, ax=axs_cm[i])\n",
    "        axs_cm[i].set_title(f\"{layers} Layers\")\n",
    "        axs_cm[i].set_xlabel(\"Predicted\")\n",
    "        axs_cm[i].set_ylabel(\"Actual\")\n",
    "\n",
    "        ax_roc.plot(fpr, tpr, label=f\"{layers} Layers (AUC={roc_auc:.2f})\")\n",
    "\n",
    "    ax_roc.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    ax_roc.set_title(\"ROC Curves by Model\")\n",
    "    ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "    ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "    ax_roc.legend()\n",
    "\n",
    "    fig_cm.suptitle(\"Confusion Matrices by Model\", fontsize=14)\n",
    "    fig_roc.tight_layout()\n",
    "    fig_cm.tight_layout()\n",
    "\n",
    "    cm_path = f\"{save_prefix}_confusion_combined.png\"\n",
    "    roc_path = f\"{save_prefix}_roc_combined.png\"\n",
    "\n",
    "    fig_cm.savefig(cm_path, dpi=300)\n",
    "    fig_roc.savefig(roc_path, dpi=300)\n",
    "    plt.close(fig_cm)\n",
    "    plt.close(fig_roc)\n",
    "\n",
    "    return cm_path, roc_path\n",
    "\n",
    "def plot_confusion_only(y_true, y_pred, title_prefix, filename_prefix):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    labels = [\"Non-Usability\", \"Usability\"]\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f\"{title_prefix} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = f\"{filename_prefix}_confusion_only.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "    return filename\n",
    "\n",
    "\n",
    "def plot_roc_only(y_true, y_prob, title_prefix, filename_prefix):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\", color=\"blue\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.title(f\"{title_prefix} - ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    filename = f\"{filename_prefix}_roc_only.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close()\n",
    "    return filename\n",
    "\n",
    "\n",
    "def plot_combined_confusion_and_roc(models_outputs, save_prefix=\"combined\"):\n",
    "    \"\"\"\n",
    "    Generates:\n",
    "    - A single figure with 3 side-by-side confusion matrices\n",
    "    - A single ROC plot with all 3 curves overlayed\n",
    "\n",
    "    models_outputs: List of tuples (layers, y_true, y_pred, y_prob, fpr, tpr, auc)\n",
    "    \"\"\"\n",
    "\n",
    "    # 📌 Confusion Matrix Grid\n",
    "    fig_cm, axs_cm = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    labels = [\"Non-Usability\", \"Usability\"]\n",
    "\n",
    "    for i, (layers, y_true, y_pred, y_prob, fpr, tpr, roc_auc) in enumerate(models_outputs):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels, ax=axs_cm[i])\n",
    "        axs_cm[i].set_title(f\"{layers} Layers\")\n",
    "        axs_cm[i].set_xlabel(\"Predicted\")\n",
    "        axs_cm[i].set_ylabel(\"Actual\")\n",
    "\n",
    "    fig_cm.suptitle(\"Confusion Matrices for All Configurations\", fontsize=14)\n",
    "    fig_cm.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    cm_path = f\"{save_prefix}_confusion_combined.png\"\n",
    "    fig_cm.savefig(cm_path, dpi=300)\n",
    "    plt.close(fig_cm)\n",
    "\n",
    "    # 📈 ROC Curve Overlay\n",
    "    fig_roc, ax_roc = plt.subplots(figsize=(6, 5))\n",
    "    for layers, _, _, _, fpr, tpr, roc_auc in models_outputs:\n",
    "        ax_roc.plot(fpr, tpr, label=f\"{layers} Layers (AUC = {roc_auc:.2f})\")\n",
    "    ax_roc.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    ax_roc.set_title(\"ROC Curves for All Configurations\")\n",
    "    ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "    ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "    ax_roc.legend(loc=\"lower right\")\n",
    "    fig_roc.tight_layout()\n",
    "    roc_path = f\"{save_prefix}_roc_combined.png\"\n",
    "    fig_roc.savefig(roc_path, dpi=300)\n",
    "    plt.close(fig_roc)\n",
    "\n",
    "    return cm_path, roc_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Evaluate and collect results\n",
    "results = []\n",
    "for layers in [2, 4, 6]:\n",
    "    model_path = f\"unfreeze_{layers}_best_model.pt\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"❌ Missing: {model_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n🔍 Evaluating: {model_path}\")\n",
    "    model = BertBinaryClassifier().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].unsqueeze(1).to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            preds = (probs > 0.5).long()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"✅ Inference completed in {elapsed:.2f} seconds\")\n",
    "\n",
    "    y_true = [int(x) for x in all_labels]\n",
    "    y_pred = [int(x) for x in all_preds]\n",
    "    y_prob = [float(p) for p in all_probs]\n",
    "\n",
    "    # Save confusion + ROC combined plot\n",
    "    filename, fpr, tpr, roc_auc = plot_confusion_and_roc(\n",
    "        y_true, y_prob, y_pred,\n",
    "        title_prefix=f\"Unfreeze {layers} Layers\",\n",
    "        filename_prefix=f\"confusion_roc_unfreeze_{layers}\"\n",
    "    )\n",
    "    print(f\"📊 Saved: {filename}\")\n",
    "\n",
    "    # Save confusion-only plot\n",
    "    filename_cm = plot_confusion_only(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        title_prefix=f\"Unfreeze {layers} Layers\",\n",
    "        filename_prefix=f\"confusion_unfreeze_{layers}\"\n",
    "    )\n",
    "    print(f\"🟦 Saved confusion-only plot: {filename_cm}\")\n",
    "\n",
    "    # Save ROC-only plot\n",
    "    filename_roc = plot_roc_only(\n",
    "        y_true=y_true,\n",
    "        y_prob=y_prob,\n",
    "        title_prefix=f\"Unfreeze {layers} Layers\",\n",
    "        filename_prefix=f\"roc_unfreeze_{layers}\"\n",
    "    )\n",
    "    print(f\"🟩 Saved ROC-only plot: {filename_roc}\")\n",
    "\n",
    "    # Store for combined plots\n",
    "    results.append((layers, y_true, y_pred, y_prob, fpr, tpr, roc_auc))\n",
    "\n",
    "cm_path, roc_path = plot_combined_confusion_and_roc(results, save_prefix=\"final\")\n",
    "print(\"🖼️ Combined confusion matrix saved to:\", cm_path)\n",
    "print(\"📈 Combined ROC curves saved to:\", roc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb57fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curves for all models separately and merge them into one image\n",
    "def plot_roc_curves_side_by_side(models_outputs, save_prefix=\"roc_curves_side_by_side\"):\n",
    "    fig, axs = plt.subplots(1, len(models_outputs), figsize=(15, 5))\n",
    "    \n",
    "    for i, (layers, _, _, _, fpr, tpr, roc_auc) in enumerate(models_outputs):\n",
    "        axs[i].plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\", color=\"blue\")\n",
    "        axs[i].plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "        axs[i].set_title(f\"{layers} Layers - ROC Curve\")\n",
    "        axs[i].set_xlabel(\"False Positive Rate\")\n",
    "        axs[i].set_ylabel(\"True Positive Rate\")\n",
    "        axs[i].legend()\n",
    "    \n",
    "    fig.suptitle(\"ROC Curves for by Model\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "    filename = f\"{save_prefix}.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.close(fig)\n",
    "    return filename\n",
    "\n",
    "roc_curves_side_by_side_path = plot_roc_curves_side_by_side(results)\n",
    "print(\"📈 Side-by-side ROC curves saved to:\", roc_curves_side_by_side_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
