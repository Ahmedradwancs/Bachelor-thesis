# ğŸ“ Automated Detection of Usability Issues Tech-Support Data
**Bachelor Thesis â€“ Kristianstad University**

| Item | Detail |
|------|--------|
| **Authors** | Ahmed Radwan Â· Jwan Mardini |
| **Supervisor** | Kamilla Klonowska |
| **Examiner**  | Craig Lindley |
| **Semester**  | Spring 2025 |
| **Industry Partner** | ***XXX*** |

---

## ğŸ“Œ Thesis Title
**A Classification-Based Approach to Detecting Usability Issues in Technical Support Data Using Zero-Shot LLM Labelling and BERT Fine-Tuning**


---

## ğŸ§­ Project Overview
The company provided an archive of â‰ˆ 235,000 tech support tickets.  
We developed a pipeline to identify usability-related issues in technical support data using:

Our pipeline:

1. **Zero-shot labelling** with an internal **71 B-parameter LLaMA-3 LLM**  
2. **Expert spot-check** on 50 tickets (â‰ˆ 90 % agreement, Îº = 0.78)  
3. **Supervised fine-tuning** of BERT (2 / 4 / 6 unfrozen layers)  
4. **Evaluation** on a held-out test set (best model F1 = 0.82)  
5. **Workload reduction analysis** (â‰ˆ 80 % of tickets filtered before human review)

The project was carried out with ***XXX*** and leverages real-world support case data to reduce the UX review workload and uncover actionable usability insights.


---

## ğŸ—‚ï¸ Project Structure
```bash
BACHELOR-THESIS/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    
â”‚   â”‚   â”œâ”€â”€ cases.csv
â”‚   â”‚   â””â”€â”€ comments.csv
â”‚   â”œâ”€â”€ processed/-----.csv
â”‚   â”œâ”€â”€ final/--------.csv
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ usability/
â”‚   â”œâ”€â”€ ------.csv    
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ ------.png
â”‚   â”œâ”€â”€ ------.xlsx
â”‚   â”œâ”€â”€ ------.csv
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ api_keys.py
â”‚   â”œâ”€â”€ utils.py
â”œâ”€â”€ 01_clean_cases.ipynb
â”œâ”€â”€ 02_clean_comments.ipynb
â”œâ”€â”€ 03_merge_cases_comments.ipynb
â”œâ”€â”€ 04_labelling_combined_dataset.ipynb
â”œâ”€â”€ 05_fine-tuning_BERT.ipynb
â”œâ”€â”€ 06_BERT_training_metrics-visualization.ipynb
â”‚
â”œâ”€â”€ xx_subcategorizing_usability_cases.ipynb
â”œâ”€â”€ experiment_results.csv
â”‚
â”œâ”€â”€ prisma_llm.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .venv/
â”œâ”€â”€ _pycache_/
â””â”€â”€ .gitignore

```
---

## âš™ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/BACHELOR-THESIS.git
cd BACHELOR-THESIS
```


### 2. Set Up a Virtual Environment (Optional)


```bash
python -m venv .venv
source venv\Scripts\activate       # On Mac:.venv/bin/activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

## ğŸš€ Execution Steps

### ğŸ”¹ 1. Data Preparation
- Run `01_clean_cases.ipynb` to clean ticket descriptions.
- Run `02_clean_comments.ipynb` to clean tech support comments.
- Run `03_merge_cases_comments.ipynb` to combine cleaned data into a single dataset.

### ğŸ”¹ 2. LLM-Assisted Labeling
- Execute `04_labelling_combined_dataset.ipynb` to apply LLM zero-shot labeling using the 71B LLaMA-3 model.
- Saves a labeled dataset for supervised learning.

### ğŸ”¹ 3. BERT Fine-Tuning
- Run `05_fine-tuning_BERT.ipynb` to train a BERT classifier on the labeled dataset.
- The notebook explores freezing different numbers of layers (2, 4, 6) for performance tuning.

### ğŸ”¹ 4. Evaluation and Visualization
- Use `06_BERT_training_metrics-visualization.ipynb` to plot training loss, accuracy, and compute evaluation metrics (F1, precision, recall).

---
## ğŸ“ˆ Results Summary

| Unfrozen Layers | Accuracy | F1 Score | Precision | Recall | Training Time (s) |
|-----------------|----------|----------|-----------|--------|-------------------|
| 2               | 0.8896   | 0.8140   | 0.8144    | 0.8136 | 52,710.92         |
| 4               | 0.8930   | 0.8181   | 0.8259    | 0.8105 | 37,450.00         |
| 6               | 0.8913   | 0.8200   | 0.8072    | 0.8332 | 34,845.31         |

The best **F1 score** and **recall** were achieved with **6 unfrozen layers**, while **4 unfrozen layers** provided the highest precision. All models demonstrated strong classification ability, with AUC scores above 0.94. The 6-layer model was preferred for its overall balance between performance and efficiency.

Approximately **80% of support cases** were filtered out as non-usability by the zero-shot LLM stage, substantially reducing the workload for UX review.

## ğŸ–¼ï¸ BERT model comparison

![Metrics comparison](results/bert_metrics_by_metric_type.png)

---

## ğŸ§ª Additional Notes

- The labeling phase used a **71B parameter LLaMA-3-based model** deployed internally at ***XXX***.
- The input for classification included both the **original support case description** and associated **comment history**, which improved label quality from ~50% to ~90% agreement with UX experts.
- All case records were **anonymized** before processing, with personal data (names, emails, IPs, etc.) removed via a regex and named entity recognition (NER) pipeline using spaCy.
- The entire pipeline, from zero-shot labeling to BERT training, was executed securely within ***XXXâ€™s internal infrastructure*** in accordance with GDPR and under a **non-disclosure agreement**.
- The trained classifier is designed for **internal UX research use only** and is not deployed in any customer-facing environment.

- `prisma.py` includes LLM prompt logic and PRISMA-guided labeling.
- `xx_subcategorizing_usability_cases.ipynb` is used for optional analysis of usability issue types to help the future work of subcategorizing the usability cases.
- Training and evaluation leverage Hugging Face Transformers and scikit-learn.
- Model training and evaluation were carried out entirely within ***XXX*** managed infrastructure.
- This solution supports internal UX improvement only and is not intended for production deployment or customer-facing systems.

---

## ğŸ“„ License

This project is part of a university thesis in collaboration with a company and not intended for commercial use.


## ğŸ§  Acknowledgments
Thanks to our supervisor Kamilla Klonowska, our examiner Craig Lindley, and the UX Design team at ***XXX*** for their feedback and support throughout the project.


## ğŸ‘¥ Contributors
- [Ahmed Radwan](https://github.com/Ahmedradwancs)
- [Jwan Mardini](https://github.com/JwanMardini)