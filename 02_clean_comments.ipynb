{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech Support Case Cleaning and Anonymization Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Imports & Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import langid\n",
    "from langdetect import detect, DetectorFactory\n",
    "import spacy\n",
    "from langdetect import detect\n",
    "import langid\n",
    "from spacy.language import Language\n",
    "import en_core_web_sm\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from presidio_analyzer import AnalyzerEngine\n",
    "from presidio_anonymizer import AnonymizerEngine\n",
    "import openpyxl\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scripts.utils import (\n",
    "    load_or_convert_to_csv, save_processed, log_time, remove_exact_duplicates,\n",
    "    is_english_langdetect, is_english_langid, detect_language_spacy,\n",
    "    anonymize_text, replace_name_patterns, read_processed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data\n",
    "comments_df = load_or_convert_to_csv(\"comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the info of the dataframe\n",
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "print(\"Initial shape:\", comments_df.shape)\n",
    "display(comments_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ 3. Initial Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "initial_count = len(comments_df)\n",
    "comments_df = comments_df[comments_df['message_body'].notna() & (comments_df['message_body'].str.strip() != \"\")]\n",
    "log_time(start, \"Removed empty or null comments\")\n",
    "print(f\"‚úÖ Removed {initial_count - len(comments_df)} comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df, removed_comments = remove_exact_duplicates(\n",
    "    comments_df,\n",
    "    subset=[\"case_number\", \"message_body\"],\n",
    "    save_prefix=\"comments\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîí Anonymization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Apply spaCy-based entity anonymization\n",
    "start = time.time()\n",
    "comments_df[\"message_body\"] = comments_df[\"message_body\"].apply(anonymize_text)\n",
    "log_time(start, \"‚úÖ Entity-based anonymization applied\")\n",
    "\n",
    "# Step 2: Apply rule-based name pattern anonymization\n",
    "start = time.time()\n",
    "comments_df[\"message_body\"] = comments_df[\"message_body\"].apply(replace_name_patterns)\n",
    "log_time(start, \"‚úÖ Name patterns replaced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç 5. Language Detection Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå Apply all three language detection methods\n",
    "comments_df[\"is_english_langdetect\"] = comments_df[\"message_body\"].apply(is_english_langdetect)\n",
    "comments_df[\"is_english_langid\"] = comments_df[\"message_body\"].apply(is_english_langid)\n",
    "comments_df[\"lang_spacy\"] = comments_df[\"message_body\"].apply(detect_language_spacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Inspect disagreement\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n",
    "\n",
    "# Messages where langid says NOT English but spaCy says English\n",
    "display(comments_df[\n",
    "    (comments_df[\"lang_spacy\"] == \"en\") & (comments_df[\"is_english_langid\"] == False)\n",
    "][[\"message_body\", \"lang_spacy\", \"is_english_langid\"]].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messages where langid says English but spaCy does NOT\n",
    "display(comments_df[\n",
    "    (comments_df[\"lang_spacy\"] != \"en\") & (comments_df[\"is_english_langid\"] == True)\n",
    "][[\"message_body\", \"lang_spacy\", \"is_english_langid\"]].head(30))\n",
    "\n",
    "# üßÆ Stats: agreement/disagreement\n",
    "print(\"üßÆ Disagreement rate (spaCy says EN, langid says not):\",\n",
    "      comments_df[(comments_df[\"lang_spacy\"] == \"en\") & (comments_df[\"is_english_langid\"] == False)].shape[0] / comments_df.shape[0])\n",
    "\n",
    "print(\"üßÆ Agreement rate (both say EN):\",\n",
    "      comments_df[(comments_df[\"lang_spacy\"] == \"en\") & (comments_df[\"is_english_langid\"] == True)].shape[0] / comments_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Final filtering: Keep if either spaCy or langid says English\n",
    "comments_df = comments_df[\n",
    "    (comments_df[\"lang_spacy\"] == \"en\") | (comments_df[\"is_english_langid\"] == True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "comments_df.drop(columns=[\"is_english_langdetect\", \"is_english_langid\", \"lang_spacy\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the info of the dataframe\n",
    "comments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "save_processed(comments_df, \"comments.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
